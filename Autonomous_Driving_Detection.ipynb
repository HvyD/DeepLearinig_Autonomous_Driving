{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autonomous Driving Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda, Conv2D\n",
    "from keras.models import load_model, Model\n",
    "from yolo_utils import read_classes, read_anchors, generate_colors, preprocess_image, draw_boxes, scale_boxes\n",
    "from yad2k.models.keras_yolo import yolo_head, yolo_boxes_to_corners, preprocess_true_boxes, yolo_loss, yolo_body\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold = .6):\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    box_classes = K.argmax(box_scores, axis=-1)\n",
    "    box_class_scores = K.max(box_scores, axis=-1)\n",
    "    filtering_mask = (box_class_scores >= threshold)\n",
    "    boxes = tf.boolean_mask(boxes, filtering_mask)\n",
    "    scores = tf.boolean_mask(box_class_scores, filtering_mask)\n",
    "    classes = tf.boolean_mask(box_classes, filtering_mask)\n",
    "    \n",
    "    return boxes, scores, classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as test_a:\n",
    "    boxes = tf.random_normal([19, 19, 5, 4], mean=1, stddev=4, seed = 1)\n",
    "    box_confidence = tf.random_normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1)\n",
    "    box_class_probs = tf.random_normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1)\n",
    "    boxes, scores, classes = yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold = 0.5)\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"boxes.shape = \" + str(boxes.shape))\n",
    "    print(\"scores.shape = \" + str(scores.shape))\n",
    "    print(\"classes.shape = \" + str(classes.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    xi1 = max(box1[0], box2[0])\n",
    "    yi1 = min(box1[1], box2[1])\n",
    "    xi2 = min(box1[2], box2[2])\n",
    "    yi2 = max(box1[3], box2[3])\n",
    "    inter_area = (xi2 - xi1) * (yi1 - yi2) \n",
    "    box1_area = (box1[2] - box1[0]) * (box1[1] - box1[3])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[1] - box2[3])\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    iou = inter_area / union_area\n",
    "\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1 = (1, 4, 3, 2)\n",
    "box2 = (2, 3, 4, 1)\n",
    "print(\"iou = \" + str(iou(box1, box2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_non_max_suppression(boxes, scores, classes, max_boxes = 10, iou_threshold = 0.5):\n",
    "\n",
    "    max_boxes_tensor = K.variable(max_boxes, dtype='int32')     # tensor to be used in tf.image.non_max_suppression()\n",
    "    K.get_session().run(tf.variables_initializer([max_boxes_tensor])) # initialize variable max_boxes_tensor\n",
    "    \n",
    "    nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes_tensor, iou_threshold=iou_threshold)\n",
    "   \n",
    "    boxes = K.gather(boxes, nms_indices)\n",
    "    scores = K.gather(scores, nms_indices)\n",
    "    classes = K.gather(classes, nms_indices)\n",
    "    \n",
    "    \n",
    "    return boxes, scores, classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as test_b:\n",
    "    boxes = tf.random_normal([54, 4], mean=1, stddev=4, seed = 1)\n",
    "    scores = tf.random_normal([54,], mean=1, stddev=4, seed = 1)\n",
    "    classes = tf.random_normal([54,], mean=1, stddev=4, seed = 1)\n",
    "    boxes, scores, classes = yolo_non_max_suppression(boxes, scores, classes)\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"boxes.shape = \" + str(boxes.eval().shape))\n",
    "    print(\"scores.shape = \" + str(scores.eval().shape))\n",
    "    print(\"classes.shape = \" + str(classes.eval().shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_eval(yolo_outputs, image_shape = (720., 1280.), max_boxes=10, score_threshold=.6, iou_threshold=.5):\n",
    "\n",
    "    # Retrieve outputs of the YOLOv2 model\n",
    "    box_xy, box_wh, box_confidence, box_class_probs = yolo_outputs\n",
    "\n",
    "    # Convert boxes to be ready for filtering functions\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "\n",
    "    # Score-filtering\n",
    "    boxes, scores, classes = yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold=score_threshold)\n",
    "    \n",
    "    # Scale boxes back to original image shape.\n",
    "    boxes = scale_boxes(boxes, image_shape)\n",
    "\n",
    "    # Non-max suppression\n",
    "    boxes, scores, classes = yolo_non_max_suppression(boxes, scores, classes, max_boxes, iou_threshold)\n",
    "    \n",
    "  \n",
    "    \n",
    "    return boxes, scores, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as test_b:\n",
    "    yolo_outputs = (tf.random_normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random_normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random_normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random_normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1))\n",
    "    boxes, scores, classes = yolo_eval(yolo_outputs)\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"boxes.shape = \" + str(boxes.eval().shape))\n",
    "    print(\"scores.shape = \" + str(scores.eval().shape))\n",
    "    print(\"classes.shape = \" + str(classes.eval().shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_names = read_classes(\"model_data/coco_classes.txt\")\n",
    "anchors = read_anchors(\"model_data/yolo_anchors.txt\")\n",
    "image_shape = (720., 1280.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = load_model(\"model_data/yolo.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes, scores, classes = yolo_eval(yolo_outputs, image_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sess, image_file):\n",
    "\n",
    "    # Preprocess your image\n",
    "    image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (608, 608))\n",
    "\n",
    "    # Run the session with the correct tensors and choose the correct placeholders in the feed_dict.\n",
    "  \n",
    "    out_boxes, out_scores, out_classes = sess.run([boxes, scores, classes],\n",
    "                                                  feed_dict={yolo_model.input: image_data, K.learning_phase(): 0})\n",
    " \n",
    "\n",
    "    # Print predictions info\n",
    "    print('Found {} boxes for {}'.format(len(out_boxes), image_file))\n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    colors = generate_colors(class_names)\n",
    "    # Draw bounding boxes on the image file\n",
    "    draw_boxes(image, out_boxes, out_scores, out_classes, class_names, colors)\n",
    "    # Save the predicted bounding box on the image\n",
    "    image.save(os.path.join(\"out\", image_file), quality=90)\n",
    "    # Display the results in the notebook\n",
    "    output_image = scipy.misc.imread(os.path.join(\"out\", image_file))\n",
    "    imshow(output_image)\n",
    "    \n",
    "    return out_boxes, out_scores, out_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_boxes, out_scores, out_classes = predict(sess, \"test.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = get_classes(\"model_data/kian_classes.txt\")\n",
    "anchors = get_anchors(\"model_data/yolo_anchors.txt\")\n",
    "data = np.load(\"underwater_data.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors_mask, matching_true_boxes = get_detector_mask(boxes, anchors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_body, model = create_model(anchors, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, class_names, anchors, image_data, boxes, detectors_mask, matching_true_boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(model_body, class_names, anchors,image_data, image_set='val', weights_name='trained_stage_3_best.h5',save_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _main(args):\n",
    "\n",
    "    # Arg parsers converted into notebook global variables\n",
    "    data_path = \"data/underwater_data.npz\"\n",
    "    anchor_path = \"model_data/yolo_anchors.txt\"\n",
    "    classes_path = \"data/underwater_classes.txt\"\n",
    "\n",
    "    class_names = get_classes(classes_path)\n",
    "    anchors = get_anchors(anchors_path)\n",
    "    data = np.load(data_path) # custom data saved as a numpy file.\n",
    "    #  has 2 arrays: an object array 'boxes' (variable length of boxes in each image)\n",
    "    #  and an array of images 'images'\n",
    "\n",
    "    image_data, boxes = process_data(data['images'], data['boxes'])\n",
    "    anchors = YOLO_ANCHORS\n",
    "    detectors_mask, matching_true_boxes = get_detector_mask(boxes, anchors)\n",
    "\n",
    "    model_body, model = create_model(anchors, class_names)\n",
    "\n",
    "    train(model, class_names, anchors, image_data, boxes, detectors_mask, matching_true_boxes)\n",
    "\n",
    "    # assumes training/validation split is 0.9\n",
    "    draw(model_body, class_names, anchors,image_data, image_set='val', weights_name='trained_stage_3_best.h5',\n",
    "        save_all=False)\n",
    "\n",
    "\n",
    "def get_classes(classes_path):\n",
    "\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    \n",
    "    if os.path.isfile(anchors_path):\n",
    "        with open(anchors_path) as f:\n",
    "            anchors = f.readline()\n",
    "            anchors = [float(x) for x in anchors.split(',')]\n",
    "            return np.array(anchors).reshape(-1, 2)\n",
    "    else:\n",
    "        Warning(\"Could not open anchors file, using default.\")\n",
    "        return YOLO_ANCHORS\n",
    "\n",
    "def process_data(images, boxes=None):\n",
    "    \n",
    "    images = [PIL.Image.fromarray(i) for i in images]\n",
    "    orig_size = np.array([images[0].width, images[0].height])\n",
    "    orig_size = np.expand_dims(orig_size, axis=0)\n",
    "\n",
    "    # Image preprocessing.\n",
    "    processed_images = [i.resize((416, 416), PIL.Image.BICUBIC) for i in images]\n",
    "    processed_images = [np.array(image, dtype=np.float) for image in processed_images]\n",
    "    processed_images = [image/255. for image in processed_images]\n",
    "\n",
    "    if boxes is not None:\n",
    "        # Box preprocessing.\n",
    "        # Original boxes stored as 1D list of class, x_min, y_min, x_max, y_max.\n",
    "        boxes = [box.reshape((-1, 5)) for box in boxes]\n",
    "        # Get extents as y_min, x_min, y_max, x_max, class for comparision with\n",
    "        # model output.\n",
    "        boxes_extents = [box[:, [2, 1, 4, 3, 0]] for box in boxes]\n",
    "\n",
    "        # Get box parameters as x_center, y_center, box_width, box_height, class.\n",
    "        boxes_xy = [0.5 * box[:, 3:5] + box[:, 1:3] for box in boxes]\n",
    "        boxes_wh = [box[:, 3:5] - box[:, 1:3] for box in boxes]\n",
    "        boxes_xy = [boxxy / orig_size for boxxy in boxes_xy]\n",
    "        boxes_wh = [boxwh / orig_size for boxwh in boxes_wh]\n",
    "        boxes = [np.concatenate((boxes_xy[i], boxes_wh[i], box[:, 0:1]), axis=1) for i, box in enumerate(boxes)]\n",
    "\n",
    "        # find the max number of boxes\n",
    "        max_boxes = 0\n",
    "        for boxz in boxes:\n",
    "            if boxz.shape[0] > max_boxes:\n",
    "                max_boxes = boxz.shape[0]\n",
    "\n",
    "        # add zero pad for training\n",
    "        for i, boxz in enumerate(boxes):\n",
    "            if boxz.shape[0]  < max_boxes:\n",
    "                zero_padding = np.zeros( (max_boxes-boxz.shape[0], 5), dtype=np.float32)\n",
    "                boxes[i] = np.vstack((boxz, zero_padding))\n",
    "\n",
    "        return np.array(processed_images), np.array(boxes)\n",
    "    else:\n",
    "        return np.array(processed_images)\n",
    "\n",
    "def get_detector_mask(boxes, anchors):\n",
    "    \n",
    "    detectors_mask = [0 for i in range(len(boxes))]\n",
    "    matching_true_boxes = [0 for i in range(len(boxes))]\n",
    "    for i, box in enumerate(boxes):\n",
    "        detectors_mask[i], matching_true_boxes[i] = preprocess_true_boxes(box, anchors, [416, 416])\n",
    "\n",
    "    return np.array(detectors_mask), np.array(matching_true_boxes)\n",
    "\n",
    "def create_model(anchors, class_names, load_pretrained=True, freeze_body=True):\n",
    "    \n",
    "\n",
    "    detectors_mask_shape = (13, 13, 5, 1)\n",
    "    matching_boxes_shape = (13, 13, 5, 5)\n",
    "\n",
    "    # Create model input layers.\n",
    "    image_input = Input(shape=(416, 416, 3))\n",
    "    boxes_input = Input(shape=(None, 5))\n",
    "    detectors_mask_input = Input(shape=detectors_mask_shape)\n",
    "    matching_boxes_input = Input(shape=matching_boxes_shape)\n",
    "\n",
    "    # Create model body.\n",
    "    yolo_model = yolo_body(image_input, len(anchors), len(class_names))\n",
    "    topless_yolo = Model(yolo_model.input, yolo_model.layers[-2].output)\n",
    "\n",
    "    if load_pretrained:\n",
    "        # Save topless yolo:\n",
    "        topless_yolo_path = os.path.join('model_data', 'yolo_topless.h5')\n",
    "        if not os.path.exists(topless_yolo_path):\n",
    "            print(\"CREATING TOPLESS WEIGHTS FILE\")\n",
    "            yolo_path = os.path.join('model_data', 'yolo.h5')\n",
    "            model_body = load_model(yolo_path)\n",
    "            model_body = Model(model_body.inputs, model_body.layers[-2].output)\n",
    "            model_body.save_weights(topless_yolo_path)\n",
    "        topless_yolo.load_weights(topless_yolo_path)\n",
    "\n",
    "    if freeze_body:\n",
    "        for layer in topless_yolo.layers:\n",
    "            layer.trainable = False\n",
    "    final_layer = Conv2D(len(anchors)*(5+len(class_names)), (1, 1), activation='linear')(topless_yolo.output)\n",
    "\n",
    "    model_body = Model(image_input, final_layer)\n",
    "\n",
    "    # Place model loss on CPU to reduce GPU memory usage.\n",
    "    with tf.device('/cpu:0'):\n",
    "        # Replace Lambda with custom Keras layer for loss.\n",
    "        model_loss = Lambda(\n",
    "            yolo_loss,\n",
    "            output_shape=(1, ),\n",
    "            name='yolo_loss',\n",
    "            arguments={'anchors': anchors,\n",
    "                       'num_classes': len(class_names)})([\n",
    "                           model_body.output, boxes_input,\n",
    "                           detectors_mask_input, matching_boxes_input\n",
    "                       ])\n",
    "\n",
    "    model = Model(\n",
    "        [model_body.input, boxes_input, detectors_mask_input,\n",
    "         matching_boxes_input], model_loss)\n",
    "\n",
    "    return model_body, model\n",
    "\n",
    "def train(model, class_names, anchors, image_data, boxes, detectors_mask, matching_true_boxes, validation_split=0.1):\n",
    "   \n",
    "    model.compile(\n",
    "        optimizer='adam', loss={\n",
    "            'yolo_loss': lambda y_true, y_pred: y_pred\n",
    "        })  # This is a hack to use the custom loss function in the last layer.\n",
    "\n",
    "    model.fit([image_data, boxes, detectors_mask, matching_true_boxes],\n",
    "              np.zeros(len(image_data)),\n",
    "              validation_split=validation_split,\n",
    "              batch_size=32,\n",
    "              epochs=5)\n",
    "    model.save_weights('trained_stage_1.h5')\n",
    "\n",
    "    model_body, model = create_model(anchors, class_names, load_pretrained=False, freeze_body=False)\n",
    "\n",
    "    model.load_weights('trained_stage_1.h5')\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam', loss={\n",
    "            'yolo_loss': lambda y_true, y_pred: y_pred\n",
    "        })  # This is a hack to use the custom loss function in the last layer.\n",
    "\n",
    "\n",
    "    model.fit([image_data, boxes, detectors_mask, matching_true_boxes],\n",
    "              np.zeros(len(image_data)),\n",
    "              validation_split=0.1,\n",
    "              batch_size=8,\n",
    "              epochs=30)\n",
    "\n",
    "    model.save_weights('trained_stage_2.h5')\n",
    "\n",
    "    model.fit([image_data, boxes, detectors_mask, matching_true_boxes],\n",
    "              np.zeros(len(image_data)),\n",
    "              validation_split=0.1,\n",
    "              batch_size=8,\n",
    "              epochs=30)\n",
    "\n",
    "    model.save_weights('trained_stage_3.h5')\n",
    "\n",
    "def draw(model_body, class_names, anchors, image_data, image_set='val',\n",
    "            weights_name='trained_stage_3_best.h5', out_path=\"output_images\", save_all=True):\n",
    "    '''\n",
    "    Draw bounding boxes on image data\n",
    "    '''\n",
    "    if image_set == 'train':\n",
    "        image_data = np.array([np.expand_dims(image, axis=0)\n",
    "            for image in image_data[:int(len(image_data)*.9)]])\n",
    "    elif image_set == 'val':\n",
    "        image_data = np.array([np.expand_dims(image, axis=0)\n",
    "            for image in image_data[int(len(image_data)*.9):]])\n",
    "    elif image_set == 'all':\n",
    "        image_data = np.array([np.expand_dims(image, axis=0)\n",
    "            for image in image_data])\n",
    "    else:\n",
    "        ValueError(\"draw argument image_set must be 'train', 'val', or 'all'\")\n",
    "    # model.load_weights(weights_name)\n",
    "    print(image_data.shape)\n",
    "    model_body.load_weights(weights_name)\n",
    "\n",
    "    # Create output variables for prediction.\n",
    "    yolo_outputs = yolo_head(model_body.output, anchors, len(class_names))\n",
    "    input_image_shape = K.placeholder(shape=(2, ))\n",
    "    boxes, scores, classes = yolo_eval(\n",
    "        yolo_outputs, input_image_shape, score_threshold=0.07, iou_threshold=0)\n",
    "\n",
    "    # Run prediction on overfit image.\n",
    "    sess = K.get_session()  # TODO: Remove dependence on Tensorflow session.\n",
    "\n",
    "    if  not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "    for i in range(len(image_data)):\n",
    "        out_boxes, out_scores, out_classes = sess.run(\n",
    "            [boxes, scores, classes],\n",
    "            feed_dict={\n",
    "                model_body.input: image_data[i],\n",
    "                input_image_shape: [image_data.shape[2], image_data.shape[3]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "        print('Found {} boxes for image.'.format(len(out_boxes)))\n",
    "        print(out_boxes)\n",
    "\n",
    "        # Plot image with predicted boxes.\n",
    "        image_with_boxes = draw_boxes(image_data[i][0], out_boxes, out_classes,\n",
    "                                    class_names, out_scores)\n",
    "        # Save the image:\n",
    "        if save_all or (len(out_boxes) > 0):\n",
    "            image = PIL.Image.fromarray(image_with_boxes)\n",
    "            image.save(os.path.join(out_path,str(i)+'.png'))\n",
    "\n",
    "        # To display (pauses the program):\n",
    "        # plt.imshow(image_with_boxes, interpolation='nearest')\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = argparser.parse_args()\n",
    "    _main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_file in os.listdir(test_path):\n",
    "    \n",
    "    image_type = imghdr.what(os.path.join(test_path, image_file))\n",
    "\n",
    "    image = Image.open(os.path.join(test_path, image_file))\n",
    "    resized_image = image.resize(tuple(reversed(model_image_size)), Image.BICUBIC)\n",
    "    image_data = np.array(resized_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "    out_boxes, out_scores, out_classes = sess.run([boxes, scores, classes],\n",
    "        feed_dict={yolo_model.input: image_data,\n",
    "                   input_image_shape: [image.size[1], image.size[0]],\n",
    "                   K.learning_phase(): 0})\n",
    "    \n",
    "    print('Found {} boxes for {}'.format(len(out_boxes), image_file))\n",
    "\n",
    "    font = ImageFont.truetype(font='font/FiraMono-Medium.otf',size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "    thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "        predicted_class = class_names[c]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        label_size = draw.textsize(label, font)\n",
    "\n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "        print(label, (left, top), (right, bottom))\n",
    "\n",
    "        if top - label_size[1] >= 0:\n",
    "            text_origin = np.array([left, top - label_size[1]])\n",
    "        else:\n",
    "            text_origin = np.array([left, top + 1])\n",
    "\n",
    "        # My kingdom for a good redistributable image drawing library.\n",
    "        for i in range(thickness):\n",
    "            draw.rectangle(\n",
    "                [left + i, top + i, right - i, bottom - i],\n",
    "                outline=colors[c])\n",
    "        draw.rectangle(\n",
    "            [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "            fill=colors[c])\n",
    "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "        del draw\n",
    "\n",
    "    image.save(os.path.join(output_path, image_file), quality=90)\n",
    "sess.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
